# üìã –°–¢–ê–ù–î–ê–†–¢–ò–ó–û–í–ê–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –ù–ê–í–ß–ê–ù–ù–Ø

## –î–ª—è —á–µ—Å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

–í—Å—ñ –º–æ–¥–µ–ª—ñ —Ç—Ä–µ–Ω—É—é—Ç—å—Å—è –∑ **–û–î–ù–ê–ö–û–í–ò–ú–ò** –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:

---

## üéØ –§–Ü–ö–°–û–í–ê–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò (–æ–¥–Ω–∞–∫–æ–≤—ñ –¥–ª—è –≤—Å—ñ—Ö)

```python
# Dataset
DATASET = "data/sudoku.csv"
TRAIN_SPLIT = 0.8
LIMIT = None  # –í–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç (1M+)

# Training
EPOCHS = 40  # –û–¥–Ω–∞–∫–æ–≤–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö –¥–ª—è –≤—Å—ñ—Ö
BATCH_SIZE = 64  # –û–¥–Ω–∞–∫–æ–≤–∏–π batch size
LEARNING_RATE = 0.001  # –û–¥–Ω–∞–∫–æ–≤–∏–π –ø–æ—á–∞—Ç–∫–æ–≤–∏–π LR
WEIGHT_DECAY = 1e-5  # –û–¥–Ω–∞–∫–æ–≤–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è

# Optimizer
OPTIMIZER = "Adam"

# Scheduler
SCHEDULER = "ReduceLROnPlateau"
SCHEDULER_PATIENCE = 3
SCHEDULER_FACTOR = 0.5

# Device
DEVICE = "cuda" if available else "cpu"

# Other
NUM_WORKERS = 0
SAVE_DIR = "weights"
```

---

## üîß –ú–û–î–ï–õ–¨-–°–ü–ï–¶–ò–§–Ü–ß–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò

–¶—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤–∏–∑–Ω–∞—á–∞—é—Ç—å –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É, –∞–ª–µ –Ω–µ –≤–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ñ—Å—Ç—å:

### CNN Baseline
```python
--model baseline
--hidden-channels 64  # –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ
```

### CNN Advanced
```python
--model advanced
--hidden-channels 128  # –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ
--num-residual-blocks 20  # –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ
```

### GNN
```python
--model gnn
--hidden-channels 128  # –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ
--num-gnn-layers 8  # –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ
```

### RNN
```python
--model rnn
# embedding_dim=64, hidden_size=128, num_layers=2
# (–∑–∞–¥–∞–Ω—ñ –≤ models/rnn_model.py)
```

---

## üìä –ö–û–ú–ê–ù–î–ò –î–õ–Ø –ù–ê–í–ß–ê–ù–ù–Ø (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω—ñ)

### CNN Baseline
```bash
python train.py \
    --model baseline \
    --epochs 40 \
    --batch-size 64 \
    --lr 0.001 \
    --hidden-channels 64 \
    --device cuda \
    --weight-decay 1e-5 \
    --save-dir weights
```

### CNN Advanced
```bash
python train.py \
    --model advanced \
    --epochs 40 \
    --batch-size 64 \
    --lr 0.001 \
    --hidden-channels 128 \
    --num-residual-blocks 20 \
    --device cuda \
    --weight-decay 1e-5 \
    --save-dir weights
```

### GNN
```bash
python train.py \
    --model gnn \
    --epochs 40 \
    --batch-size 64 \
    --lr 0.001 \
    --hidden-channels 128 \
    --num-gnn-layers 8 \
    --device cuda \
    --weight-decay 1e-5 \
    --save-dir weights
```

### RNN
```bash
python train.py \
    --model rnn \
    --epochs 40 \
    --batch-size 64 \
    --lr 0.001 \
    --device cuda \
    --weight-decay 1e-5 \
    --save-dir weights
```

---

## ‚úÖ –©–æ –û–î–ù–ê–ö–û–í–ï (—á–µ—Å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è):

- ‚úÖ –î–∞—Ç–∞—Å–µ—Ç: `data/sudoku.csv` (–≤–µ—Å—å)
- ‚úÖ Train/Val split: 80/20
- ‚úÖ Epochs: 40
- ‚úÖ Batch size: 64
- ‚úÖ Learning rate: 0.001
- ‚úÖ Optimizer: Adam
- ‚úÖ Weight decay: 1e-5
- ‚úÖ Scheduler: ReduceLROnPlateau (patience=3, factor=0.5)
- ‚úÖ Gradient clipping: max_norm=1.0 (–≤ train.py –¥–ª—è –≤—Å—ñ—Ö)
- ‚úÖ Device: CUDA (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ)
- ‚úÖ Random seed: (–º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ)

---

## üîç –©–æ –†–Ü–ó–ù–ï (–∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ):

- üîß –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ (–ø—Ä–∏—Ä–æ–¥–Ω–∞ —Ä—ñ–∑–Ω–∏—Ü—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä)
- üîß Hidden channels (64 –¥–ª—è baseline, 128 –¥–ª—è —ñ–Ω—à–∏—Ö)
- üîß –ö—ñ–ª—å–∫—ñ—Å—Ç—å —à–∞—Ä—ñ–≤ (5 –¥–ª—è baseline, 20 –¥–ª—è advanced, 8 –¥–ª—è GNN, 2 –¥–ª—è RNN)

**–¶–µ –û–ö!** –¶–µ –ø—Ä–∏—Ä–æ–¥–Ω—ñ –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä, –∞ –Ω–µ –Ω–µ—á–µ—Å–Ω—ñ —É–º–æ–≤–∏.

---

## üìù –ü–†–ò–ú–Ü–¢–ö–ò:

1. **Batch size 64** - —Ü–µ –∫–æ–º–ø—Ä–æ–º—ñ—Å:
   - –î–ª—è baseline —Ü–µ –º–æ–∂–µ –±—É—Ç–∏ –±—ñ–ª—å—à–µ (128)
   - –î–ª—è GNN —Ü–µ –º–æ–∂–µ –±—É—Ç–∏ –º–µ–Ω—à–µ (32)
   - –ê–ª–µ 64 –¥–æ–∑–≤–æ–ª—è—î –≤—Å—ñ–º –º–æ–¥–µ–ª—è–º —Ç—Ä–µ–Ω—É–≤–∞—Ç–∏—Å—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ

2. **40 epochs** - –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π:
   - Baseline –∫–æ–Ω–≤–µ—Ä–≥—É—î –∑–∞ ~20-25 epochs
   - Advanced –∫–æ–Ω–≤–µ—Ä–≥—É—î –∑–∞ ~30-35 epochs
   - GNN –∫–æ–Ω–≤–µ—Ä–≥—É—î –∑–∞ ~35-40 epochs
   - RNN –∫–æ–Ω–≤–µ—Ä–≥—É—î –∑–∞ ~25-30 epochs

3. **Gradient clipping** –≤–∂–µ —î –≤ `train.py` (—Ä—è–¥–æ–∫ 100):
   ```python
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
   ```
   –¶–µ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î—Ç—å—Å—è –¥–æ –í–°–Ü–• –º–æ–¥–µ–ª–µ–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.

---

## üéØ –†–ï–ó–£–õ–¨–¢–ê–¢:

–ü—ñ—Å–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –≤—Å—ñ—Ö 4 –º–æ–¥–µ–ª–µ–π –∑ —Ü–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –≤–∏ –æ—Ç—Ä–∏–º–∞—î—Ç–µ **—á–µ—Å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è**, –¥–µ —Ä—ñ–∑–Ω–∏—Ü—è –≤ accuracy –±—É–¥–µ –æ–±—É–º–æ–≤–ª–µ–Ω–∞ –¢–Ü–õ–¨–ö–ò –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é –º–æ–¥–µ–ª—ñ, –∞ –Ω–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–∞–≤—á–∞–Ω–Ω—è!

---

## üìä –û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (–∑ –æ–¥–Ω–∞–∫–æ–≤–∏–º–∏ —É–º–æ–≤–∞–º–∏):

| –ú–æ–¥–µ–ª—å | Cell Accuracy | Board Accuracy | –ü—Ä–∏—á–∏–Ω–∞ |
|--------|---------------|----------------|---------|
| **CNN Baseline** | ~85-88% | ~30-35% | –û–±–º–µ–∂–µ–Ω–∏–π receptive field |
| **CNN Advanced** | ~92-94% | ~60-70% | –ì–ª–∏–±–æ–∫–∞ –º–µ—Ä–µ–∂–∞, skip connections |
| **GNN** | ~93-95% | ~65-75% | –ì—Ä–∞—Ñ–æ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, attention |
| **RNN** | ~80-85% | ~25-30% | –í—Ç—Ä–∞—Ç–∞ 2D —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ |

–†—ñ–∑–Ω–∏—Ü—è –≤ accuracy —Ç–µ–ø–µ—Ä –ø–æ–∫–∞–∑—É—î **—Ä–µ–∞–ª—å–Ω—É —Ä—ñ–∑–Ω–∏—Ü—é –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä**!
