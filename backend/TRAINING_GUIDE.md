# üìö –ü–æ—Å—ñ–±–Ω–∏–∫ –∑ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π

## üéØ –ö–ª—é—á–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è

### ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –ø—ñ—Å–ª—è –ö–û–ñ–ù–û–á –µ–ø–æ—Ö–∏

**–†–∞–Ω—ñ—à–µ:**
- ‚ùå History –∑–±–µ—Ä—ñ–≥–∞–≤—Å—è —Ç—ñ–ª—å–∫–∏ –≤ –∫—ñ–Ω—Ü—ñ –≤—Å—ñ—Ö 40 –µ–ø–æ—Ö
- ‚ùå –ü—Ä–∏ –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è –≤—Ç—Ä–∞—á–∞–ª–∞—Å—è –í–°–Ø —ñ—Å—Ç–æ—Ä—ñ—è
- ‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –±—É–ª–æ –≤—ñ–¥–Ω–æ–≤–∏—Ç–∏ –≥—Ä–∞—Ñ—ñ–∫–∏

**–¢–µ–ø–µ—Ä:**
- ‚úÖ History –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –ø—ñ—Å–ª—è –ö–û–ñ–ù–û–á –µ–ø–æ—Ö–∏
- ‚úÖ –ü—Ä–∏ –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è - –≤—Å—è —ñ—Å—Ç–æ—Ä—ñ—è –∑–±–µ—Ä–µ–∂–µ–Ω–∞
- ‚úÖ –ü–æ–≤–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏

### ‚úÖ –ü–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç–∞–Ω—É –¥–ª—è resume

**–©–æ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ checkpoint:**
- ‚úÖ Model weights (–≤–∞–≥–∏ –º–µ—Ä–µ–∂—ñ)
- ‚úÖ Optimizer state (momentum, learning rate per parameter)
- ‚úÖ Scheduler state (patience counter, best loss, cooldown)
- ‚úÖ RNG states (Python, NumPy, PyTorch, CUDA)
- ‚úÖ Epoch number
- ‚úÖ Best validation loss
- ‚úÖ Training arguments

**–ß–æ–º—É —Ü–µ –≤–∞–∂–ª–∏–≤–æ:**
- Reproducible training (–æ–¥–Ω–∞–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ resume)
- –ö–æ—Ä–µ–∫—Ç–Ω–∞ —Ä–æ–±–æ—Ç–∞ scheduler (–Ω–µ –∑–∞–±—É–≤–∞—î patience counter)
- –ü—Ä–∞–≤–∏–ª—å–Ω–∏–π shuffle –¥–∞—Ç–∞—Å–µ—Ç—É (–ø—Ä–æ–¥–æ–≤–∂—É—î –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –ø–æ–∑–∏—Ü—ñ—ó)

---

## üíæ –¢–∏–ø–∏ checkpoint —Ñ–∞–π–ª—ñ–≤

### `model_last.pth` - –î–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è (Resume)

**–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:** –û—Å—Ç–∞–Ω–Ω—ñ–π —Å—Ç–∞–Ω –º–æ–¥–µ–ª—ñ –¥–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è

**–ú—ñ—Å—Ç–∏—Ç—å:**
- –û—Å—Ç–∞–Ω–Ω—é –∑–±–µ—Ä–µ–∂–µ–Ω—É –µ–ø–æ—Ö—É
- –ê–∫—Ç—É–∞–ª—å–Ω–∏–π optimizer state
- –ê–∫—Ç—É–∞–ª—å–Ω–∏–π scheduler state (patience counter)
- –ü–æ—Ç–æ—á–Ω—ñ RNG states

**–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è:**
```bash
# –ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
python train.py --model baseline --resume weights/baseline_last.pth --epochs 40
```

‚ö†Ô∏è **–ó–ê–í–ñ–î–ò –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ `*_last.pth` –¥–ª—è resume, –∞ –ù–ï `*_best.pth`!**

---

### `model_best.pth` - –î–ª—è inference —Ç–∞ –æ—Ü—ñ–Ω–∫–∏

**–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:** –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –∑–∞ validation loss

**–ú—ñ—Å—Ç–∏—Ç—å:**
- –ï–ø–æ—Ö—É –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º val_loss
- Optimizer/scheduler state –∑ —Ç—ñ—î—ó –µ–ø–æ—Ö–∏
- RNG states –∑ —Ç—ñ—î—ó –µ–ø–æ—Ö–∏

**–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è:**
```bash
# –§—ñ–Ω–∞–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
python evaluate.py --model baseline --checkpoint weights/baseline_best.pth

# –î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–Ω
python main.py  # API –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î best.pth
```

**–ü—Ä–∏–º—ñ—Ç–∫–∞:** `best.pth` –º–æ–∂–µ –±—É—Ç–∏ –∑—ñ —Å—Ç–∞—Ä—ñ—à–æ—ó –µ–ø–æ—Ö–∏ –Ω—ñ–∂ `last.pth`

**–ü—Ä–∏–∫–ª–∞–¥:**
```
–ï–ø–æ—Ö–∞ 30: val_loss = 0.42 ‚Üí –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ best.pth
–ï–ø–æ—Ö–∞ 31: val_loss = 0.44 (–≥—ñ—Ä—à–µ)
–ï–ø–æ—Ö–∞ 32: val_loss = 0.45 (–≥—ñ—Ä—à–µ)

–†–µ–∑—É–ª—å—Ç–∞—Ç:
- best.pth = –µ–ø–æ—Ö–∞ 30 (val_loss 0.42)
- last.pth = –µ–ø–æ—Ö–∞ 32 (val_loss 0.45)
```

---

## üìä –©–æ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è

### –ü—ñ—Å–ª—è –∫–æ–∂–Ω–æ—ó –µ–ø–æ—Ö–∏:

```
weights/
  model_last.pth           # Checkpoint –¥–ª—è resume
  model_best.pth           # –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å
  model_history.json       # ‚Üê –û–ù–û–í–õ–Æ–Ñ–¢–¨–°–Ø –ö–û–ñ–ù–û–á –ï–ü–û–•–ò! ‚úÖ
```

### –ö–æ–∂–Ω—ñ 10 –µ–ø–æ—Ö (backup):

```
weights/
  model_epoch_10.pth       # Backup –Ω–∞ –µ–ø–æ—Å—ñ 10
  model_epoch_20.pth       # Backup –Ω–∞ –µ–ø–æ—Å—ñ 20
  model_epoch_30.pth       # Backup –Ω–∞ –µ–ø–æ—Å—ñ 30
  model_epoch_40.pth       # Backup –Ω–∞ –µ–ø–æ—Å—ñ 40
```

---

## üîÑ –ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è (Resume)

### –ü—Ä–∏ –∑–∞–ø—É—Å–∫—É –∑ --resume:

```bash
python train.py \
    --model baseline \
    --epochs 40 \
    --resume weights/baseline_last.pth \
    ...
```

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è:**

1. ‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é—Ç—å—Å—è –≤–∞–≥–∏ –º–æ–¥–µ–ª—ñ
2. ‚úÖ –í—ñ–¥–Ω–æ–≤–ª—é—î—Ç—å—Å—è —Å—Ç–∞–Ω optimizer (momentum, per-parameter learning rates)
3. ‚úÖ –í—ñ–¥–Ω–æ–≤–ª—é—î—Ç—å—Å—è —Å—Ç–∞–Ω scheduler (patience counter, best loss, cooldown)
4. ‚úÖ –í—ñ–¥–Ω–æ–≤–ª—é—é—Ç—å—Å—è RNG states (Python, NumPy, PyTorch, CUDA)
5. ‚úÖ **–ó–ê–í–ê–ù–¢–ê–ñ–£–Ñ–¢–¨–°–Ø —ñ—Å—Ç–æ—Ä—ñ—è –∑ JSON —Ñ–∞–π–ª—É**
6. ‚úÖ –ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –¥–æ–¥–∞—î –Ω–æ–≤—ñ –µ–ø–æ—Ö–∏ –¥–æ —ñ—Å–Ω—É—é—á–æ—ó —ñ—Å—Ç–æ—Ä—ñ—ó

**–í–∏–≤—ñ–¥:**
```
üîÑ Loading checkpoint from weights/baseline_last.pth...
   ‚úì Scheduler state restored
   ‚úì RNG states restored (reproducible training)
‚úÖ Checkpoint loaded. Resuming from epoch 26.
   Previous best validation loss: 0.3421
   Loaded training history: 25 previous epochs

Epoch 26/40
------------------------------------------------------------
...
```

**–ß–æ–º—É scheduler state –≤–∞–∂–ª–∏–≤–∏–π:**

Scheduler `ReduceLROnPlateau` –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É—î —Å–∫—ñ–ª—å–∫–∏ –µ–ø–æ—Ö validation loss –Ω–µ –ø–æ–∫—Ä–∞—â—É—î—Ç—å—Å—è:
- –ë–µ–∑ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è: scheduler "–∑–∞–±—É–≤–∞—î" patience counter ‚Üí –º–æ–∂–µ –∑–º–µ–Ω—à–∏—Ç–∏ LR –ø–µ—Ä–µ–¥—á–∞—Å–Ω–æ –∞–±–æ –∑–∞–ø—ñ–∑–Ω–æ
- –ó –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è–º: scheduler –ø—Ä–æ–¥–æ–≤–∂—É—î –∫–æ—Ä–µ–∫—Ç–Ω–æ –≤—ñ–¥—Å–ª—ñ–¥–∫–æ–≤—É–≤–∞—Ç–∏ patience

**–ß–æ–º—É RNG states –≤–∞–∂–ª–∏–≤—ñ:**

- –ì–∞—Ä–∞–Ω—Ç—É—é—Ç—å –æ–¥–Ω–∞–∫–æ–≤–∏–π shuffle –¥–∞—Ç–∞—Å–µ—Ç—É –ø—Ä–∏ resume
- –ì–∞—Ä–∞–Ω—Ç—É—é—Ç—å –æ–¥–Ω–∞–∫–æ–≤–∏–π dropout mask
- –ó–∞–±–µ–∑–ø–µ—á—É—é—Ç—å reproducibility (–æ–¥–Ω–∞–∫–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–∏ –æ–¥–Ω–∞–∫–æ–≤–æ–º—É seed)

---

## üìà –°—Ç—Ä—É–∫—Ç—É—Ä–∞ history.json

```json
[
  {
    "epoch": 1,
    "train": {
      "loss": 0.5432,
      "cell_accuracy": 0.7856,
      "empty_cell_accuracy": 0.6543,
      "board_accuracy": 0.1234
    },
    "val": {
      "loss": 0.4987,
      "cell_accuracy": 0.8012,
      "empty_cell_accuracy": 0.6789,
      "board_accuracy": 0.1567
    },
    "lr": 0.001
  },
  {
    "epoch": 2,
    ...
  }
]
```

**–í—Å—ñ –¥–∞–Ω—ñ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ —Ç–∞ –∞–Ω–∞–ª—ñ–∑—É! ‚úÖ**

---

## üö® –°—Ü–µ–Ω–∞—Ä—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –°—Ü–µ–Ω–∞—Ä—ñ–π 1: –ù–æ—Ä–º–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è (40 –µ–ø–æ—Ö –±–µ–∑ –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è)

```bash
python train.py --model baseline --epochs 40 ...
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ `baseline_history.json` –∑ —É—Å—ñ–º–∞ 40 –µ–ø–æ—Ö–∞–º–∏
- ‚úÖ –ü–æ–≤–Ω—ñ –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏

---

### –°—Ü–µ–Ω–∞—Ä—ñ–π 2: –ù–∞–≤—á–∞–Ω–Ω—è –ø–µ—Ä–µ—Ä–≤–∞–ª–æ—Å—è –Ω–∞ –µ–ø–æ—Å—ñ 25

**–©–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ:**
```
weights/
  baseline_last.pth           # –ï–ø–æ—Ö–∞ 25
  baseline_best.pth           # –ù–∞–π–∫—Ä–∞—â–∞ –µ–ø–æ—Ö–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 20)
  baseline_history.json       # –ï–ø–æ—Ö–∏ 1-25 ‚úÖ
  baseline_epoch_10.pth       # Backup
  baseline_epoch_20.pth       # Backup
```

**–ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è:**
```bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç—ñ—Ç—å runtime –≤ Colab
# –ó–º–æ–Ω—Ç—É–π—Ç–µ Drive
from google.colab import drive
drive.mount('/content/drive')
%cd /content/drive/MyDrive/diplom/backend

# –ü—Ä–æ–¥–æ–≤–∂—ñ—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
!python train.py \
    --model baseline \
    --epochs 40 \
    --resume weights/baseline_last.pth \
    --batch-size 64 \
    --lr 0.001 \
    --hidden-channels 64 \
    --device cuda \
    --weight-decay 1e-5 \
    --limit 1000000 \
    --save-dir weights
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
üîÑ Loading checkpoint from weights/baseline_last.pth...
‚úÖ Checkpoint loaded. Resuming from epoch 26.
   Loaded training history: 25 previous epochs  ‚Üê –Ü–°–¢–û–†–Ü–Ø –í–Ü–î–ù–û–í–õ–ï–ù–ê!

Epoch 26/40
...
Epoch 40/40

üìä Training history saved: weights/baseline_history.json
   Total epochs: 40  ‚Üê –í–°–Ü 40 –ï–ü–û–• –í –Ü–°–¢–û–†–Ü–á!
```

---

### –°—Ü–µ–Ω–∞—Ä—ñ–π 3: –•–æ—á–µ—Ç–µ –Ω–∞–≤—á–∞—Ç–∏ –¥–æ–≤—à–µ (—â–µ +20 –µ–ø–æ—Ö)

```bash
# –ü—ñ—Å–ª—è 40 –µ–ø–æ—Ö, –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –¥–æ 60:
python train.py \
    --model baseline \
    --epochs 60 \              # ‚Üê –ë—É–ª–æ 40, —Å—Ç–∞–ª–æ 60
    --resume weights/baseline_last.pth \
    ...
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- `baseline_history.json` –∑ –µ–ø–æ—Ö–∞–º–∏ 1-60
- Backup –Ω–∞ –µ–ø–æ—Ö–∞—Ö 10, 20, 30, 40, 50, 60

---

## üíæ Backup —Ñ–∞–π–ª–∏

### –°—Ç–≤–æ—Ä—é—é—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∫–æ–∂–Ω—ñ 10 –µ–ø–æ—Ö:

**–ß–æ–º—É —Ü–µ –∫–æ—Ä–∏—Å–Ω–æ:**
- –ú–æ–∂–Ω–∞ –≤—ñ–¥–∫–æ—Ç–∏—Ç–∏—Å—è –¥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –µ–ø–æ—Ö–∏
- –ó–∞—Ö–∏—Å—Ç –≤—ñ–¥ –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏—Ö checkpoint
- –ú–æ–∂–Ω–∞ –ø–æ—Ä—ñ–≤–Ω—è—Ç–∏ –º–æ–¥–µ–ª—å –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –µ—Ç–∞–ø–∞—Ö

**–Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ backup:**
```bash
# –Ø–∫—â–æ last.pth –ø–æ—à–∫–æ–¥–∂–µ–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ backup:
python train.py \
    --model baseline \
    --epochs 40 \
    --resume weights/baseline_epoch_20.pth \  # ‚Üê Backup –µ–ø–æ—Ö–∏ 20
    ...
```

---

## üéì –î–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏

### –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ —Ñ–∞–π–ª–∏ –¥–ª—è –∑–≤—ñ—Ç—É:

```
weights/
  ‚úÖ baseline_history.json      # –í–°–Ø —ñ—Å—Ç–æ—Ä—ñ—è (40 –µ–ø–æ—Ö)
  ‚úÖ baseline_best.pth           # –ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å
  ‚úÖ advanced_history.json
  ‚úÖ advanced_best.pth
  ‚úÖ gnn_history.json
  ‚úÖ gnn_best.pth
  ‚úÖ rnn_history.json
  ‚úÖ rnn_best.pth
```

### –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ –Ω–æ—É—Ç–±—É–∫–∞—Ö –∞–Ω–∞–ª—ñ–∑—É:

```python
# Train_CNN_Baseline.ipynb, –ö—Ä–æ–∫ 4: –ê–Ω–∞–ª—ñ–∑
import json

with open('weights/baseline_history.json', 'r') as f:
    history = json.load(f)

# –°—Ç–≤–æ—Ä–∏—Ç–∏ –≥—Ä–∞—Ñ—ñ–∫–∏
epochs = [h['epoch'] for h in history]
train_loss = [h['train']['loss'] for h in history]
val_loss = [h['val']['loss'] for h in history]

plt.plot(epochs, train_loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Val Loss')
plt.show()
```

---

## ‚ö†Ô∏è –í–∞–∂–ª–∏–≤–æ

### –ù–µ –≤–∏–¥–∞–ª—è–π—Ç–µ history.json –ø–µ—Ä–µ–¥ resume!

**–ü–æ–≥–∞–Ω–æ:**
```bash
!rm weights/baseline_history.json  # ‚ùå –ù–ï –†–û–ë–Ü–¢–¨ –¶–ï!
!python train.py --resume weights/baseline_last.pth ...
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –Ü—Å—Ç–æ—Ä—ñ—è –ø–æ—á–Ω–µ—Ç—å—Å—è –∑ –µ–ø–æ—Ö–∏ 26 (–≤—Ç—Ä–∞—á–µ–Ω–æ –µ–ø–æ—Ö–∏ 1-25)

**–î–æ–±—Ä–µ:**
```bash
# –ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç—ñ—Ç—å –∑ --resume
!python train.py --resume weights/baseline_last.pth ...
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –Ü—Å—Ç–æ—Ä—ñ—è –ø—Ä–æ–¥–æ–≤–∂–∏—Ç—å—Å—è (–µ–ø–æ—Ö–∏ 1-40 –≤—Å—ñ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ)

---

## üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ—Å—Ç–æ—Ä—ñ—ó

### –°–∫—ñ–ª—å–∫–∏ –µ–ø–æ—Ö –∑–±–µ—Ä–µ–∂–µ–Ω–æ:

```python
import json

with open('weights/baseline_history.json', 'r') as f:
    history = json.load(f)

print(f"üìä –ó–±–µ—Ä–µ–∂–µ–Ω–æ –µ–ø–æ—Ö: {len(history)}")
print(f"   –ü–µ—Ä—à–∞ –µ–ø–æ—Ö–∞: {history[0]['epoch']}")
print(f"   –û—Å—Ç–∞–Ω–Ω—è –µ–ø–æ—Ö–∞: {history[-1]['epoch']}")
print(f"   –§—ñ–Ω–∞–ª—å–Ω–∞ val accuracy: {history[-1]['val']['cell_accuracy']:.4f}")
```

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –µ–ø–æ—Ö–∏:

```python
epochs = [h['epoch'] for h in history]
expected = list(range(1, len(history) + 1))

if epochs == expected:
    print("‚úÖ –í—Å—ñ –µ–ø–æ—Ö–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ, –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫—ñ–≤")
else:
    missing = set(expected) - set(epochs)
    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω—ñ –µ–ø–æ—Ö–∏: {missing}")
```

---

## üéâ –ü—ñ–¥—Å—É–º–æ–∫

### –©–æ –∑–º—ñ–Ω–∏–ª–æ—Å—è:

| –§—É–Ω–∫—Ü—ñ—è | –†–∞–Ω—ñ—à–µ | –¢–µ–ø–µ—Ä |
|---------|--------|-------|
| **–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è history** | ‚ùå –¢—ñ–ª—å–∫–∏ –≤ –∫—ñ–Ω—Ü—ñ | ‚úÖ –ü—ñ—Å–ª—è –∫–æ–∂–Ω–æ—ó –µ–ø–æ—Ö–∏ |
| **Resume + history** | ‚ùå –Ü—Å—Ç–æ—Ä—ñ—è –≤—Ç—Ä–∞—á–∞–ª–∞—Å—è | ‚úÖ –Ü—Å—Ç–æ—Ä—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è |
| **Backup checkpoint** | ‚ùå –ù–µ–º–∞—î | ‚úÖ –ö–æ–∂–Ω—ñ 10 –µ–ø–æ—Ö |
| **–î–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó** | ‚ö†Ô∏è –†–∏–∑–∏–∫–æ–≤–∞–Ω–æ | ‚úÖ –ë–µ–∑–ø–µ—á–Ω–æ |

### –ü–µ—Ä–µ–≤–∞–≥–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏:

- ‚úÖ **–ü–æ–≤–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è** (–≤—Å—ñ 40 –µ–ø–æ—Ö)
- ‚úÖ **–ì—Ä–∞—Ñ—ñ–∫–∏ –≤—ñ–¥ –ø–æ—á–∞—Ç–∫—É –¥–æ –∫—ñ–Ω—Ü—è**
- ‚úÖ **–ú–æ–∂–ª–∏–≤—ñ—Å—Ç—å –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è** –±–µ–∑ –≤—Ç—Ä–∞—Ç–∏ –¥–∞–Ω–∏—Ö
- ‚úÖ **Backup –Ω–∞ –≤–∏–ø–∞–¥–æ–∫ –ø–æ–º–∏–ª–æ–∫**
- ‚úÖ **–ß–µ—Å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π**

**–¢–µ–ø–µ—Ä –Ω–∞–≤—á–∞–Ω–Ω—è –ø–æ–≤–Ω—ñ—Å—Ç—é –±–µ–∑–ø–µ—á–Ω–µ –¥–ª—è –≤–∞—à–æ—ó –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏! üöÄ**
