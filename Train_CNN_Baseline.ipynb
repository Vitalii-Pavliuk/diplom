{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî∑ CNN Baseline - –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è\n",
    "\n",
    "**–ú–æ–¥–µ–ª—å:** Simple Convolutional Neural Network  \n",
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:** ~60,000  \n",
    "**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:** –®–≤–∏–¥–∫–∞, –ø—Ä–æ—Å—Ç–∞, –º–∞–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (–æ–¥–Ω–∞–∫–æ–≤—ñ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π):\n",
    "- **Epochs:** 40 ‚úÖ\n",
    "- **Batch size:** 64 ‚úÖ\n",
    "- **Learning rate:** 0.001 ‚úÖ\n",
    "- **Weight decay:** 1e-5 ‚úÖ\n",
    "- **Optimizer:** Adam ‚úÖ\n",
    "- **Scheduler:** ReduceLROnPlateau ‚úÖ\n",
    "- **Dataset:** 1M+ puzzles (–≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç) ‚úÖ\n",
    "\n",
    "## üîß –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –¥–ª—è CNN Baseline):\n",
    "- **Hidden channels:** 64\n",
    "- **Conv layers:** 5\n",
    "\n",
    "**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 85-88% cell accuracy, 30-35% board accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ –ö—Ä–æ–∫ 1: –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "\n",
    "# PyTorch (—Å—Ç–∞–±—ñ–ª—å–Ω–∞ –≤–µ—Ä—Å—ñ—è)\n",
    "!pip uninstall torch torchvision torchaudio -y -q\n",
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121 -q\n",
    "\n",
    "# –î–æ–¥–∞—Ç–∫–æ–≤—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏\n",
    "!pip install tqdm pandas numpy matplotlib scikit-learn -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ GPU\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU not available, will use CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ –ö—Ä–æ–∫ 2: –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ—î–∫—Ç—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –®–ª—è—Ö –¥–æ –ø—Ä–æ—î–∫—Ç—É (–∑–º—ñ–Ω—ñ—Ç—å –Ω–∞ —Å–≤—ñ–π!)\n",
    "PROJECT_PATH = '/content/drive/MyDrive/Diplom/backend'\n",
    "\n",
    "# –ü–µ—Ä–µ—Ö—ñ–¥ —É –ø–∞–ø–∫—É –ø—Ä–æ—î–∫—Ç—É\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—ñ–≤\n",
    "required_files = ['train.py', 'dataset.py', 'models/__init__.py', 'data/sudoku.csv']\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úÖ {file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} - NOT FOUND!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì –ö—Ä–æ–∫ 3: –ù–∞–≤—á–∞–Ω–Ω—è CNN Baseline\n",
    "\n",
    "### –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ù–ê–í–ß–ê–ù–ù–Ø CNN BASELINE ===\n",
    "# ‚öñÔ∏è –°–¢–ê–ù–î–ê–†–¢–ò–ó–û–í–ê–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò (–æ–¥–Ω–∞–∫–æ–≤—ñ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π)\n",
    "\n",
    "!python train.py \\\n",
    "    --model baseline \\\n",
    "    --epochs 40 \\\n",
    "    --batch-size 64 \\\n",
    "    --lr 0.001 \\\n",
    "    --hidden-channels 64 \\\n",
    "    --device cuda \\\n",
    "    --weight-decay 1e-5 \\\n",
    "    --limit 1000000 \\\n",
    "    --save-dir weights\n",
    "\n",
    "# üéØ –§–Ü–ö–°–û–í–ê–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò (–¥–ª—è —á–µ—Å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è):\n",
    "# --epochs 40              : –û–î–ù–ê–ö–û–í–ï –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "# --batch-size 64          : –û–î–ù–ê–ö–û–í–ï –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "# --lr 0.001               : –û–î–ù–ê–ö–û–í–ï –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "# --weight-decay 1e-5      : –û–î–ù–ê–ö–û–í–ï –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "# --limit 1000000          : –†–Ü–í–ù–û 1–ú —Å—É–¥–æ–∫—É (800–ö train + 200–ö val)\n",
    "# \n",
    "# üîß –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –¥–ª—è –º–æ–¥–µ–ª—ñ):\n",
    "# --hidden-channels 64     : –≤–∏–∑–Ω–∞—á–µ–Ω–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä –ö—Ä–æ–∫ 4: –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –Ω–∞–≤—á–∞–Ω–Ω—è\n",
    "with open('weights/baseline_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö\n",
    "epochs = [h['epoch'] for h in history]\n",
    "train_loss = [h['train']['loss'] for h in history]\n",
    "val_loss = [h['val']['loss'] for h in history]\n",
    "train_acc = [h['train']['cell_accuracy'] for h in history]\n",
    "val_acc = [h['val']['cell_accuracy'] for h in history]\n",
    "board_acc = [h['val']['board_accuracy'] for h in history]\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, train_loss, label='Train Loss', marker='o')\n",
    "axes[0].plot(epochs, val_loss, label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('CNN Baseline - Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Cell Accuracy\n",
    "axes[1].plot(epochs, train_acc, label='Train Acc', marker='o')\n",
    "axes[1].plot(epochs, val_acc, label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Cell Accuracy')\n",
    "axes[1].set_title('CNN Baseline - Cell Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Board Accuracy\n",
    "axes[2].plot(epochs, board_acc, label='Board Acc', marker='D', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Board Accuracy')\n",
    "axes[2].set_title('CNN Baseline - Board Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weights/baseline_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# –§—ñ–Ω–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä –§–Ü–ù–ê–õ–¨–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò CNN BASELINE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Validation Loss:       {min(val_loss):.4f}\")\n",
    "print(f\"Best Cell Accuracy:         {max(val_acc):.2%}\")\n",
    "print(f\"Best Board Accuracy:        {max(board_acc):.2%}\")\n",
    "print(f\"Final Cell Accuracy:        {val_acc[-1]:.2%}\")\n",
    "print(f\"Final Board Accuracy:       {board_acc[-1]:.2%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ –ö—Ä–æ–∫ 5: –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models import CNNBaseline\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNNBaseline(hidden_channels=64).to(device)\n",
    "\n",
    "checkpoint = torch.load('weights/baseline_best.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded from epoch {checkpoint['epoch']}\")\n",
    "print(f\"   Validation accuracy: {checkpoint['val_accuracy']:.2%}\")\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤–∏–π –ø–∞–∑–ª\n",
    "test_puzzle = [\n",
    "    [5, 3, 0, 0, 7, 0, 0, 0, 0],\n",
    "    [6, 0, 0, 1, 9, 5, 0, 0, 0],\n",
    "    [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
    "    [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
    "    [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
    "    [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
    "    [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
    "    [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
    "    [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
    "]\n",
    "\n",
    "# Inference\n",
    "input_tensor = torch.tensor(test_puzzle, dtype=torch.long).unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    predictions = torch.argmax(output, dim=-1).squeeze().cpu().numpy() + 1\n",
    "    \n",
    "    # Confidence\n",
    "    probs = torch.softmax(output, dim=-1)\n",
    "    confidence = probs.max(dim=-1)[0].mean().item()\n",
    "\n",
    "# –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É\n",
    "print(\"\\nüéØ –¢–ï–°–¢ –Ü–ù–§–ï–†–ï–ù–°–£\")\n",
    "print(f\"Confidence: {confidence:.2%}\\n\")\n",
    "print(\"Solved puzzle:\")\n",
    "for row in predictions:\n",
    "    print(' '.join(map(str, row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ –ö—Ä–æ–∫ 6: –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–≤—ñ—Ç—É\n",
    "report = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë         CNN BASELINE - –ó–í–Ü–¢ –ü–†–û –ù–ê–í–ß–ê–ù–ù–Ø                ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä –ê–†–•–Ü–¢–ï–ö–¢–£–†–ê\n",
    "‚îú‚îÄ –¢–∏–ø:               Simple CNN\n",
    "‚îú‚îÄ –ü–∞—Ä–∞–º–µ—Ç—Ä–∏:         ~60,000\n",
    "‚îú‚îÄ –®–∞—Ä–∏:              5 convolutional layers\n",
    "‚îî‚îÄ Hidden channels:   64\n",
    "\n",
    "üéì –ù–ê–í–ß–ê–ù–ù–Ø\n",
    "‚îú‚îÄ Epochs:            30\n",
    "‚îú‚îÄ Batch size:        128\n",
    "‚îú‚îÄ Learning rate:     0.001\n",
    "‚îú‚îÄ Optimizer:         Adam\n",
    "‚îú‚îÄ Scheduler:         ReduceLROnPlateau\n",
    "‚îî‚îÄ Device:            {device}\n",
    "\n",
    "üìà –†–ï–ó–£–õ–¨–¢–ê–¢–ò\n",
    "‚îú‚îÄ Best Val Loss:         {min(val_loss):.4f}\n",
    "‚îú‚îÄ Best Cell Accuracy:    {max(val_acc):.2%}\n",
    "‚îú‚îÄ Best Board Accuracy:   {max(board_acc):.2%}\n",
    "‚îú‚îÄ Final Cell Accuracy:   {val_acc[-1]:.2%}\n",
    "‚îî‚îÄ Final Board Accuracy:  {board_acc[-1]:.2%}\n",
    "\n",
    "üí° –í–ò–°–ù–û–í–ö–ò\n",
    "‚îî‚îÄ CNN Baseline –ø–æ–∫–∞–∑—É—î {max(val_acc):.1%} —Ç–æ—á–Ω–æ—Å—Ç—ñ –Ω–∞ –∫–ª—ñ—Ç–∏–Ω–∫–∞—Ö.\n",
    "   –¶–µ —Ö–æ—Ä–æ—à–∞ –±–∞–∑–æ–≤–∞ –ª—ñ–Ω—ñ—è –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏.\n",
    "   –ú–æ–¥–µ–ª—å —à–≤–∏–¥–∫–∞ —ñ –º–∞—î –º–∞–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.\n",
    "\n",
    "üìÅ –§–ê–ô–õ–ò\n",
    "‚îú‚îÄ weights/baseline_best.pth          - –Ω–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å\n",
    "‚îú‚îÄ weights/baseline_last.pth          - –æ—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª—å\n",
    "‚îú‚îÄ weights/baseline_history.json      - —ñ—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è\n",
    "‚îî‚îÄ weights/baseline_training_curves.png - –≥—Ä–∞—Ñ—ñ–∫–∏\n",
    "\n",
    "–î–∞—Ç–∞: {history[-1].get('timestamp', 'N/A')}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É\n",
    "with open('weights/baseline_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n‚úÖ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É weights/baseline_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ –ì–æ—Ç–æ–≤–æ!\n",
    "\n",
    "CNN Baseline –Ω–∞–≤—á–µ–Ω–∞ –∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.  \n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —É –ø–∞–ø—Ü—ñ `weights/`.\n",
    "\n",
    "**–ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫:** –ó–∞–ø—É—Å—Ç—ñ—Ç—å —ñ–Ω—à—ñ –Ω–æ—É—Ç–±—É–∫–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è:\n",
    "- `Train_CNN_Advanced.ipynb`\n",
    "- `Train_GNN.ipynb`\n",
    "- `Train_RNN.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
